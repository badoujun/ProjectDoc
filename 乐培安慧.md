# 1.技术选型

jdk1.8+Mysql8.0+tomcat+FastDFS+socketMQ+Redis+springCloud+Jenkins+docker

开发工具： idea

github地址：https://github.com/badoujun/lpah.git

# 2.软件安装

## 2.1 docker

```shell
# 关于docker挂载的一些经验
1. 容器目录不可以为相对路径
2. 宿主机目录如果不存在，则会自动生成
3. 宿主机的目录如果为相对路径呢
4. 删除容器不会删除宿主机上之前作为挂载目录的文件，比如redis写入的AOF文件不会删除
```



### 2.1.1安装

1. 鉴于国内网络问题，强烈建议使用国内源,执行下面的命令添加 `yum`软件源：

```shell
sudo yum-config-manager \
    --add-repo \
    https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo
```

2. 如果需要最新版本的 Docker CE 请使用以下命令:

```shell
sudo yum-config-manager --enable docker-ce-edge
```

3. 安装docker CE

```shell
# Docker Engine改为Docker CE（社区版）
- 它包含了CLI客户端、后台进程/服务以及API。用户像以前以同样的方式获取。
# Docker Data Center改为Docker EE（企业版） 
- 在Docker三个定价层增加了额外的支付产品和支持

```

4. 更新yum软件源缓存，并安装docker CE

```shell
 sudo yum makecache fast
 sudo yum install docker-ce
 # 默认安装目录
 cd /var/lib/docker
 # 启动docker
 systemctl enable docker.service
 systemctl start docker
```

5. 小技巧：使用脚本自动安装

> 在测试或开发环境中 Docker 官方为了简化安装流程，提供了一套便捷的安装脚本，CentOS 系统上可以使用这套脚本安装。执行这个命令后，脚本就会自动的将一切准备工作做好，并且把 Docker CE 的 Edge 版本安装在系统中。

```shell
 curl -fsSL get.docker.com -o get-docker.sh
 sudo sh get-docker.sh --mirror Aliyun
```

6. 添加docker组

> 而只有 root 用户和 docker组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root用户。因此，更好地做法是将需要使用 docker 的用户加入 docker 用户组。

```shell
#添加docker组
sudo groupadd docker 
# 将当前用户添加进docker组
sudo usermod -aG docker $USER 
# 退出当前终端，并重新登录并进行测试,输出如下内容代表设置成功
docker run hello-world
```

![1568883728868](image\1568883728868.png)

7. 镜像加速

> 鉴于国内网络问题，后续拉取 Docker 镜像十分缓慢，强烈建议安装 Docker 之后配置 `国内镜像加速`。

```shell
# 要先启动docker生成目录，默认docker配置文件在/etc/docker目录下
vim /etc/docker/daemon.json
# 添加以下内容，注意括号
{ "registry-mirrors": ["https://docker.mirrors.ustc.edu.cn"] }
```



### 2.1.2指令

```shell
# 查看是否安装成功，成功输出Docker version 19.03.2, build 6a30dfc
docker -v
# 启动
sudo service docker start
# 查看启动是否成功
 ps -ef|grep docker
# 关闭
sudo service docker stop
# 重启
sudo service docker restart
# 备份
docker save -o [tar包真实路径] [镜像名 ]
-如：docker save -o /usr/docker_data/mongo-backup.tar mongo
# 恢复
docker load -i [tar包真实路径]
-如：docker load -i /usr/docker_data/mongo-backup.tar
-------------------------------------------------- 镜像 ----------------------------------------------
# 搜索镜像
docker search redis
# 查看所有镜像
docker images
# 下载镜像
docker pull redis
# 删除镜像
docker rmi redis
-------------------------------------------------- 容器 ----------------------------------------------
- 每一个容器相当于一个单独的linux系统，里面如果没有安装docker就无法使用docker命令
# 查询所有运行容器
docker ps
# 查询所有容器包括未运行容器
docker ps -a
# 创建交互式容器，一般测试容器是否能够成功创建，退出容器就停止运行
docker run -it --name=容器名称 镜像名称 /bin/bash
# 守护式容器
docker run -di --name=容器名称 镜像名称
【例子1】
- docker run -d --name redis-server -p 6379:6379 redis --requirepass "redis123"
-- name redis-server : 指定容器名称
-- -p 6379:6379 : 端口映射
-- redis：镜像名称
-- --requitepass "redis123" : 指定redis连接密码
# 进入守护式容器
docker exec -it 容器名称 /bin/bash
# 删除容器
docker rm 容器名称
# 启动容器
docker start 容器名称
# 停止容器
docker stop 容器名称
# 重启容器
docker restart 容器名称
-------------------------------------------------- 拷贝 ----------------------------------------------
# 宿主机拷贝到容器
docker cp 宿主机目录 容器名称:容器目录
docker cp hello.txt myRedis:/usr/local
【注意】如果写宿主机目录出只有具体的文件名，就会默认以宿主机的当前目录为宿主机目录或理解为文件路径
# 容器拷贝到宿主机
docker cp 容器名称:容器目录 宿主机目录
# 目录挂载：一般都使用这种方式,
docker run -di --name=容器名称 -v 宿主机目录:容器目录 镜像命令
- docker run -di --name=myRedis -v /home/eric:/usr/local/eric redis 
```

### 2.1.3问题

1. 修改镜像文件daemon.json配置下载镜像时，发现vim /etc/docker/daemon.json打开为空不存在。该目录下只有key.json。我的解决方案是手动创建一个

```shell
vim /etc/docker/daemon.json
# 以下是粘贴的内容
{ 
  "registry-mirrors": ["https://docker.mirrors.ustc.edu.cn"]
}
```

2. 如果看到以下警告信息

```shell
WARNING: bridge-nf-call-iptables is disabled
WARNING: bridge-nf-call-ip6tables is disabled
# 那么就添加内核参数
$ sudo tee -a /etc/sysctl.conf <<-EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
```

3. 提交镜像到私服时出现Http: server gave HTTP response to HTTPS client 解决方法
4. 重启失败

> Job for docker.service failed because the control process exited with error code. See "systemctl status docker.service" and "journalctl -xe" for details.

```shell
rm -rf /var/lib/docker/  '巨坑！就是删除docker，里面的所有镜像都没了'
vim /etc/docker/daemon.json
`添加以下内容`
{ "graph": "/mnt/docker-data", "storage-driver": "overlay" }
sudo service docker start
```

> 如果还是继续出现问题：Job for docker.service failed because the control process exited with error code. See "systemctl status docker.service" and "journalctl -xe" for details.

```shell
# 执行journalctl -xe查看详情
unable to configure the Docker daemon with file /etc/docker/daemon.json: invalid character '#' looking for beginning of object key string
'就是说daemon.json文件里面有无效字符'

```

5. 执行安装第一步的时候出现以下内容

> # Could not resolve host: mirrorlist.centos.org; Unknown error

```shell
sudo vi /etc/resolv.conf
`新增一行`
nameserver 8.8.8.8
```



### 2.1.4私服

```shell
# 下载registry镜像
docker pull registry
# 运行registry
docker run -di --name=registry -p 5000:5000 registry
# 访问私服
http://106.52.164.198:5000/v2/_catalog
# 本地docker对远程docker私服添加信任
vi /etc/docker/daemon.json
"insecure-registries":["106.52.164.198:5000"]
# 重启docker
sudo service docker restart
# 手动上传-打标签
docker tag jdk1.8 106.52.164.198:5000/jdk1.8
# 手动上传-推送给私服
docker push 106.52.164.198:5000/jdk1.8
# 从私服中下载
docker pull 106.52.164.198:5000/jdk1.8
```

### 2.1.5脚本

```shell
#!/bin/bash
sudo yum-config-manager --add-repo https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo
sudo yum-config-manager --enable docker-ce-edge
sudo yum makecache fast
sudo yum install docker-ce
cd /var/lib/docker
systemctl enable docker.service
systemctl start docker
curl -fsSL get.docker.com -o get-docker.sh
sudo sh get-docker.sh --mirror Aliyun
sudo groupadd docker 
sudo usermod -aG docker $USER 
docker run hello-world
touch /etc/docker/daemon.json
echo "
{ \"registry-mirrors\": [\"https://docker.mirrors.ustc.edu.cn\"] }
" > /etc/docker/daemon.json
```

### 2.1.6防火墙

```shell
------------------------------------------- 防火墙指令 --------------------------------------------
# 查看防火墙状态
firewall-cmd --state
# 停止firewall
systemctl stop firewalld.service
# 开启防火墙
systemctl start firewalld
# 显示状态
firewall-cmd --state
# 更新防火墙
firewall-cmd --reload
# 开端口
firewall-cmd --zone=public --add-port=8080/tcp --permanent
firewall-cmd --zone=public --add-port=3306/tcp --permanent
firewall-cmd --zone=public --add-port=6379/tcp --permanent
# 查看端口
firewall-cmd --zone=public --list-ports
```



## 2.2 mysql

### 2.2.1 快速简单安装

```shell
# 下载mysql镜像
docker pull mysql 
'【注意】直接下载的是最新版的，也就是8.x版本'
# 创建守护式容器，开放端口，设置访问密码
docker run -di --name=mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql
# 因为mysql8.*的新特性 caching_sha2_password 密码加密方式，所有navicat可能会连接不上，切换回以前版本；
# caching_sha2_password和sha256_password认证插件比mysql_native_password插件提供的密码加密更加安全；
# 并且caching_sha2_password加密比sha256_password的加密性能更好。

docker exec -it mysql /bin/bash
mysql -u root -p  密码为创建容器时设置的123456
ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY '123456';
FLUSH PRIVILEGES;
# 查看一下哪些主机能访问，用户和能够访问的主机，localhost代表只能本机访问，%代表都能访问
use mysql;
select user,host from user;
# 全盘搜索带mysql字符的文件，name区分大小写，iname不区分大小写
 find / -iname *mysql*  【-type 根据文件类型查找(f文件,d目录,l软链接文件)】
 ------------------------------------------------------------------------------------------------
 # 创建用户
 mysql -u root -p 123456
 CREATE USER 'lpah'@'%' IDENTIFIED BY 'xiande';
 CREATE USER '【用户名】'@'【访问ip，%为都允许】' IDENTIFIED BY '【这里是密码】';
 # 加密方式
 ALTER USER 'lpah'@'%' IDENTIFIED WITH mysql_native_password BY 'xiande';
 FLUSH PRIVILEGES;
# 用户授权
GRANT ALL ON *.* TO 'lpah'@'%';
GRANT 【SELECT，INSERT，UPDATE等，如果要授予所的权限则使用ALL】 ON 【如果要授予该用户对所有数据库和表的相应操作权限则可用*表示，如*.*】 TO '【用户名】'@'【访问ip，%为都允许】';
# 查看所有用户
SELECT DISTINCT CONCAT('User: ''',user,'''@''',host,''';') AS query FROM mysql.user;
# 查看用户权限
show grants for 'lpah'@'%';   
```

### 2.2.2  配置文件详解

```shell
[client] 
default-character-set = utf8mb4
[mysql]
#默认的编码格式
default-character-set = utf8mb4
#端口
port=3306
#这个文件是用于socket连接的文件,使自己能够链接自己的数据库,出问题会导致mysql.service无法启动
socket=/data/mysql/mysql.sock 

[mysqld]
# 使用的用户
user=mysql
# 默认的引擎
default_storage_engine=InnoDB 
#server的文件位置
socket=/data/mysql/mysql.sock 
#进程代号为/data/mysql/mysql.pid
pid-file=/data/mysql/mysql.pid
# 时区配置
default-time_zone = '+8:00'
#key_buffer_size指定用于索引的缓冲区大小，增加它可得到更好的索引处理性能。
#对于内存在4GB左右的服务器该参数可设置为256M或384M。注意：该参数值设置的过大反而会是服务器整体效率降低！
key_buffer_size=32M

# 设置mysql的安装目录
basedir=D:/server/mysql8/

#设置mysql数据库的数据的存放目录
datadir=D:/server/mysql8/data

# 密码认证方式
default_authentication_plugin= mysql_native_password

#当链接错误达到次数为10的时候,封锁该host
max_connect_errors=10

#当客户端连接数据库服务器时，服务器会进行主机名解析，并且当DNS很慢时，建立连接也会很慢。
#因此建议在启动服务器时关闭skip_name_resolve选项而不进行DNS查找。
#唯一的局限是之后GRANT语句中只能使用IP地址了，因此在添加这项设置到一个已有系统中必须格外小心。
skip_name_resolve 


#开启该选项可以彻底关闭MySQL的TCP/IP连接方式
#如果WEB服务器是以远程连接的方式访问MySQL数据库服务器则不要开启该选项！否则将无法正常连接！
#
#skip-networking 

#mysql安装目录
datadir=/data/mysql/

`日志备份`
# 如果你想让数据库服务器充当主节点的备份节点，那么开启二进制日志是必须的。
# 如果这么做了之后，还别忘了设置server_id为一个唯一的值。
# 就算只有一个服务器如果你想做基于时间点的数据恢复，开启二进制日志也是很有用的：从你最近的备份中恢复（全量备份），并应用二进制日志中的修改（增量备份）。二进制日志一旦创建就将永久保存。所以如果你不想让磁盘空间耗尽，你可以用 PURGE BINARY LOGS 来清除旧文件，或者设置 expire_logs_days 来指定过多少天日志将被自动清除。
#记录二进制日志不是没有开销的，所以如果你在一个非主节点的复制节点上不需要它的话，那么建议关闭这个选项。
log_bin=/data/mysql/mysql-bin

# 每经过n次日志写操作就把日志文件写入硬盘一次(对日志信息进行一次同步)。
# n=1是最安全的做法，但效率最低。默认设置是n=0，意思是由操作系统来负责二进制日志文件的同步工作。
sync_binlog=1

# 指定过多少天日志将被清除
expire_logs_days=14

`缓存限制`
# 临时HEAP数据表的最大长度(默认设置是32M); 超过这个长度的临时数据表将被转换为MyISAM数据表并存入一个临时文件。
tmp_table_size=32M 
# HEAP数据表的最大长度(默认设置是16M); 超过这个长度的HEAP数据表将被存入一个临时文件而不是驻留在内存里。
max_heap_table_size=32M 

# 查询缓存区的工作模式:
# 0, 禁用查询缓存区; 1，启用查询缓存区(默认设置); 2，”按需分配”模式，只响应SELECT SQL_CACHE命令。
#query cache查询缓存是一个众所周知的瓶颈，甚至在并发并不多的时候也是如此。 
# 最佳选项是将其从一开始就停用，设置query_cache_size = 0（现在MySQL 5.6的默认值）并利用其他方法加速查询：优化索引、增加拷贝分散负载或者启用额外的缓存（比如memcache或redis）。如果你已经为你的应用启用了query cache并且还没有发现任何问题，query cache可能对你有用。这是如果你想停用它，那就得小心了。
query_cache_type=0 

# 最大连接数
#如果你经常看到‘Too many connections'错误，是因为max_connections的值太低了。
#这非常常见因为应用程序没有正确的关闭数据库连接，你需要比默认的151连接数更大的值。
max_connections=1000 

#用户连接个数限制
max_user_connections=500

thread_cache_size=50 
open_files_limit=65535 
table_definition_cache=1024 
table_open_cache=2048 

`innoDB`
#这项配置决定了数据和日志写入硬盘的方式。一般来说，如果你有硬件RAID控制器，并且其独立缓存采用write-back机制，并有着电池断电保护，那么应该设置配置为O_DIRECT；否则，大多数情况下应将其设为fdatasync（默认值）。sysbench是一个可以帮助你决定这个选项的好工具。
innodb_flush_method=O_DIRECT 

#这项配置决定了为尚未执行的事务分配的缓存。其默认值（1MB）一般来说已经够用了，但是如果你的事务中包含有二进制大对象或者大文本字段的话，这点缓存很快就会被填满并触发额外的I/O操作。
#看看Innodb_log_waits状态变量，如果它不是0，增加innodb_log_buffer_size。
innodb_log_buffer_size=1MB

innodb_log_files_in_group=2 
#这是redo日志的大小。redo日志被用于确保写操作快速而可靠并且在崩溃时恢复。
innodb_log_file_size=256M 

#默认值为1，表示InnoDB完全支持ACID特性。当你的主要关注点是数据安全的时候这个值是最合适的，比如在一个主节点上。但是对于磁盘（读写）速度较慢的系统，它会带来很巨大的开销，因为每次将改变flush到redo日志都需要额外的fsyncs。将它的值设置为2会导致不太可靠（reliable）因为提交的事务仅仅每秒才flush一次到redo日志，但对于一些场景是可以接受的，比如对于主节点的备份节点这个值是可以接受的。如果值为0速度就更快了，但在系统崩溃时可能丢失一些数据：只适用于备份节点。
innodb_flush_log_at_trx_commit=1 

#这项设置告知InnoDB是否需要将所有表的数据和索引存放在共享表空间里（innodb_file_per_table = OFF） 或者为每张表的数据单独放在一个.ibd文件（innodb_file_per_table = ON）。每张表一个文件允许你在drop、truncate或者rebuild表时回收磁盘空间。
innodb_file_per_table=1 

#这是你安装完InnoDB后第一个应该设置的选项。缓冲池是数据和索引缓存的地方：这个值越大越好，这能保证你在大多数的读取操作时使用的是内存而不是硬盘。典型的值是5-6GB(8GB内存)，20-25GB(32GB内存)，100-120GB(128GB内存)。
innodb_buffer_pool_size=3G 

# InnoDB驱动程序能够同时使用的最大线程个数(默认设置是8)。
innodb_thread_concurrency=12 

thread_handling=pool-of-threads 

`日志`
#错误日志位置为/data/mysql/mysql-error.log
log_error=/data/mysql/mysql-error.log 
# 把慢查询以及执行时没有使用索引的查询命令全都记入日志(其余同–log-slow-queries选项)
log_queries_not_using_indexes=1 
slow_query_log=1 
slow_query_log_file=/data/mysql/mysql-slow.log

#MySQL数据库及表(仅MyISAM)支持符号链接(symbolic link)，即数据库或表可以存储在my.cnf中指定datadir之外的分区或目录。
#要支持符号链接，需要在配置中设置symbolic-links=1
symbolic-links=0

# 限制数据导入导出到哪个目录
secure_file_priv = "/"

#客户与服务器之间交换的数据包的最大长度，这个数字至少应该大于客户程序将要处理的最大BLOB块的长度。
#这个选项的默认设置是1MB。
max_allowed_packet=16M 
character-set-client-handshake = FALSE
# 新数据库或数据表的默认字符集
character-set-server = utf8mb4
collation-server = utf8mb4_unicode_ci
init_connect='SET NAMES utf8mb4'
skip-character-set-client-handshake = true


```

### 2.2.3 默认配置加时区

```shell
[client] 
default-character-set = utf8
[mysql]
default-character-set = utf8
[mysqld]
socket=/usr/local/software/mysql/conf/mysql.sock 
pid-file=/usr/local/software/mysql/conf/mysql.pid
character-set-client-handshake = FALSE
character-set-server = utf8
collation-server = utf8_unicode_ci
init_connect='SET NAMES utf8'
skip-character-set-client-handshake = true
default-time_zone = '+8:00'
basedir=/usr/local/software/mysql
datadir=/usr/local/software/mysql/data
log_bin=/usr/local/software/mysql/log/mysql-bin
log_error=/usr/local/software/mysql/log/mysql-error.log 
slow_query_log_file=/usr/local/software/mysql/log/mysql-slow.log
secure_file_priv = "/"
log_queries_not_using_indexes=1 
slow_query_log=1 
query_cache_type=0 
sync_binlog=1
expire_logs_days=14
innodb_thread_concurrency=12
max_connect_errors=20
max_connections=1000
max_user_connections=500
max_allowed_packet=16M 
default_authentication_plugin= mysql_native_password
skip_name_resolve 
```

### 2.2.4 脚本安装

> 时区设置为东八区，关闭缓存（没有使用redis可以打开），开启了二进制文件备份
>
> -e 参数必须放在--name前面，否则会设置不了
>
> 【注意】每次创建容器前，需要清理挂载目录，否则无法启动，也不会报错

```shell
#!/bin/bash
docker pull mysql:latest
mkdir /usr/local/software
mkdir /usr/local/software/mysql
mkdir /usr/local/software/mysql/data
mkdir /usr/local/software/mysql/conf
mkdir /usr/local/software/mysql/log
chmod 777 /usr/local/software/mysql/data 
chmod 777 /usr/local/software/mysql/conf 
chmod 777 /usr/local/software/mysql/log 
touch /usr/local/software/mysql/conf/mysql.cnf

echo "
[client] 
default-character-set = utf8
[mysql]
default-character-set = utf8
[mysqld]
socket=/usr/local/software/mysql/conf/mysql.sock 
pid-file=/usr/local/software/mysql/conf/mysql.pid
character-set-client-handshake = FALSE
character-set-server = utf8
collation-server = utf8_unicode_ci
init_connect='SET NAMES utf8'
skip-character-set-client-handshake = true
default-time_zone = '+8:00'
basedir=/usr/local/software/mysql
datadir=/usr/local/software/mysql/data
log_bin=/usr/local/software/mysql/log/mysql-bin
log_error=/usr/local/software/mysql/log/mysql-error.log 
slow_query_log_file=/usr/local/software/mysql/log/mysql-slow.log
log_queries_not_using_indexes=1 
slow_query_log=1 
query_cache_type=0 
sync_binlog=1
expire_logs_days=14
innodb_thread_concurrency=12
max_connect_errors=20
max_connections=1000
max_user_connections=500
max_allowed_packet=16M 
default_authentication_plugin= mysql_native_password
skip_name_resolve 
" > /usr/local/software/mysql/conf/mysql.cnf

docker run -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 --name mysql -v /usr/local/software/mysql/conf:/usr/local/software/mysql/conf -v /usr/local/software/mysql/data:/usr/local/software/mysql/data  -v /usr/local/software/mysql/log:/usr/local/software/mysql/log -v /usr/local/software/mysql/mysql-files:/var/lib/mysql-files  -di mysql mysqld --defaults-file=/usr/local/software/mysql/conf/mysql.cnf --user=root 

```

### 2.2.5 问题

```shell
# 查看日志
docker logs [容器]

# 开启防火墙后启动容器出现以下错误
 driver failed programming external connectivity on endpoint mysql (9dca36377b2b5ec3263e8e3713570b979451568d771001c3ec4b8ab4cd04f30a):  (iptables failed: iptables --wait -t nat -A DOCKER -p tcp -d 0/0 --dport 3306 -j DNAT --to-destination 172.17.0.4:3306 ! -i docker0: iptables: No chain/target/match by that name.
 (exit status 1))
 `修改:重启docker`
 systemctl restart docker
 docker start mysql
 
 #  /var/lib/mysql-files目录丢失，linux下自动更新mysql导致的问题
 mysqld: Error on realpath() on '/var/lib/mysql-files' 
`原因：mysql8当指定了外部配置文件与外部存储路径时，也需要指定 /var/lib/mysql-files的外部目录。`
解决方案：启动容器时加上 '-v /opt/docker/mysql/mysql-files:/var/lib/mysql-files'
```



## 2.3 tomcat

```shell
# 下载镜像
docker pull tomcat:7-jre7
# 运行tomcat容器
docker run -di --name=tomcat7 -p 8080:8080 tomcat:7-jre7
# 目录挂载,tomcat安装容器中安装路径在/usr/local/tomcat
docker run -di --name=tomcat7 -p 8080:8080 -v /usr/local/tomcat/webapps:/usr/local/tomcat/webapps tomcat:7-jre7
# 查看是否安装完成
docker ps 
# 下载之后在webAPP下没有ROOT根目录，所以直接访问看不到tom猫
mkdir /usr/local/tomcat/webapps/ROOT
vim index.html
# 下面写一个hello-world
<html>
<body>
<h2>Hello World!</h2>
</body>
</html>
# 访问验证
106.52.164.198:8080 '出现helloworld则成功'
```

```shell
# 进入容器tomcat目录
cd /usr/local/tomcat/bin
# 关闭
./shutdown.sh
# 开启
./startup.sh
```



## 2.4 redis

### 2.4.1  简单安装测试

```shell
# 下载镜像
docker pull redis
# 运行redis容器
docker run -di --name=redis -p 6379:6379 redis
# 安装路径
cd /usr/local/bin
【注意】腾讯云开放端口，RedisDesktopManager连接，此处没有设置密码，且安装的是单机版
# 进入 redis
redis-cli


```

### 2.4.2 以配置文件启动

> 单机配置-AOF每秒保存-关闭RDB

```shell
# 默认情况下，redis 在 server 上所有有效的网络接口上监听客户端连接。
# 你如果只想让它在一个网络接口上监听，那你就绑定本机的一个IP或者多个IP。
#
# 示例，多个IP用空格隔开:
# 【一般就是本机的全部端口】
bind 0.0.0.0

# 设置redis连接密码,客户端连接需要、主从连接也可需要
requirepass test123

# 开启protected-mode保护模式，需配置bind ip或者设置访问密码
# 
protected-mode yes

# 【默认】监听端口号，默认为 6379，如果你设为 0 ，redis 将不在 socket 上监听任何客户端连接。
port 6379

# TCP 监听的最大容纳数量
#
# 在高并发的环境下，你需要把这个值调高以避免客户端连接缓慢的问题。
# Linux 内核会一声不响的把这个值缩小成 /proc/sys/net/core/somaxconn 对应的值，
# 所以你要修改这两个值才能达到你的预期。
tcp-backlog 511

# 指定在一个 client 空闲多少秒之后关闭连接（0 就是不管它）
timeout 0

# tcp 心跳包。
# 如果设置为非零，则在与客户端缺乏通讯的时候使用 SO_KEEPALIVE 发送 tcp acks 给客户端。
# 推荐一个合理的值就是60秒
tcp-keepalive 60

# 【常用:docker安装必须为no，不然redis要么启动立即结束，要么报错】
# 默认情况下 redis 不是作为守护进程运行的，如果你想让它在后台运行，你就把它改成 yes。
# 当redis作为守护进程运行的时候，它会写一个 pid 到 /var/run/redis.pid 文件里面。
daemonize no

supervised no
# 当redis作为守护进程运行的时候，它会把 pid 默认写到 /var/run/redis.pid 文件里面，
# 但是你可以在这里自己制定它的文件位置。
pidfile /usr/local/software/redis/log/redis_6379.pid

################################ 日志 ################################
# 定义日志级别。
# 可以是下面的这些值：
# debug (适用于开发或测试阶段)
# verbose (many rarely useful info, but not a mess like the debug level)
# notice (适用于生产环境)
# warning (仅仅一些重要的消息被记录)
# 【可以修改】
loglevel notice

# 【需要修改】指定日志文件的位置，如果是docker就是容器里的位置
#　可能会报Can't open the log file: Permission denied错误
logfile "/usr/local/software/redis/log/redis.log"

# 要想把日志记录到系统日志，就把它改成 yes，
# 也可以可选择性的更新其他的syslog 参数以达到你的要求
#syslog-enabled no

# 设置 syslog 的 identity。
# syslog-ident redis

# 设置 syslog 的 facility，必须是 USER 或者是 LOCAL0-LOCAL7 之间的值。
# syslog-facility local0

# 设置数据库的数目。
# 默认数据库是 DB 0，你可以在每个连接上使用 select <dbid> 命令选择一个不同的数据库，
# 但是 dbid 必须是一个介于 0 到 databasees - 1 之间的值
databases 16

# redis启动时是否显示Logo
always-show-logo yes


################################ 快照 ################################
# 存 DB 到磁盘：
#   格式：save <间隔时间（秒）> <写入次数>
#
#   根据给定的时间间隔和写入次数将数据保存到磁盘
#
#   下面的例子的意思是：
#   900 秒内如果至少有 1 个 key 的值变化，则保存
#   300 秒内如果至少有 10 个 key 的值变化，则保存
#   60 秒内如果至少有 10000 个 key 的值变化，则保存
#　　
#   注意：你可以注释掉所有的 save 行来停用保存功能。
#   也可以直接一个空字符串来实现停用：
#   
# save 900 1
# save 300 10
# save 60 10000
save ""

# 默认情况下，如果 redis 最后一次的后台保存失败，redis 将停止接受写操作，
# 这样以一种强硬的方式让用户知道数据不能正确的持久化到磁盘，
# 否则就会没人注意到灾难的发生。
#
# 如果后台保存进程重新启动工作了，redis 也将自动的允许写操作。
#
# 然而你要是安装了靠谱的监控，你可能不希望 redis 这样做，那你就改成 no 好了。
# 【可安装靠谱监控进行修改】
stop-writes-on-bgsave-error yes

# 是否在 dump .rdb 数据库的时候使用 LZF 压缩字符串
# 默认都设为 yes
# 如果你希望保存子进程节省点 cpu ，你就设置它为 no ，
# 不过这个数据集可能就会比较大
rdbcompression yes

# 启用CRC64校验码，当然这个会影响一部份性能 
rdbchecksum yes

# 设置 dump 的文件位置
dbfilename dump.rdb

# 工作目录
# 例如上面的 dbfilename 只指定了文件名，
# 但是它会写入到这个目录下。这个配置项一定是个目录，而不能是文件名
# 不管是AOF文件还是RDB文件都会在这个目录
dir /usr/local/software/redis/data


replica-serve-stale-data yes


# 如果为 yes，代表为只读状态，但并不表示客户端用集群方式连接从节点时不可以进行 set 操作
# 且 set 操作的数据不会被放在从节点的槽上，会被放到某主节点的槽上。
replica-read-only yes

# 享叔解析：使用socket方式复制数据，目前redis复制提供disk和socket两种方式，
# 如果新的slave连上来或者重连的slave无法部分同步，就会执行全量同步，master会生成rdb文件。
# disk方式：是master创建一个新的进程把rdb文件保存到磁盘，再把磁盘上的rdb文件传递给slave。
# disk方式的时候，当一个rdb保存的过程中，多个slave都能共享这个rdb文件。
# socket方式：是master创建一个新的进程，直接把rdb文件以socket的方式发给slave。
# socket的方式就的一个个slave顺序复制。在磁盘速度缓慢，网速快的情况下推荐用socket方式。
# 【网速快使用no】
repl-diskless-sync no
repl-diskless-sync-delay 5

repl-disable-tcp-nodelay no
replica-priority 100

lazyfree-lazy-eviction no
lazyfree-lazy-expire no
lazyfree-lazy-server-del no
replica-lazy-flush no

# 启用AOF模式
appendonly yes

# 设置AOF记录的文件名,只能是文件名，不能这样/usr/local/software/redis/data/redisAofLog.aof
appendfilename "redisAofLog.aof"

# 向磁盘进行数据刷写的频率，有3个选项： 
# always 有新数据则马上刷写，速度慢但可靠性高 
# everysec 每秒钟刷写一次，折衷方法，所谓的redis可以只丢失1秒钟的数据就是源于此处 
# no 按照OS自身的刷写策略来进行，速度最快 
# 
appendfsync everysec

# aof重写期间是否同步
no-appendfsync-on-rewrite no

# 重写触发配置
# aof文件触发自动rewrite的百分比，值为0则表示禁用自动rewrite
auto-aof-rewrite-percentage 100
# aof文件触发自动rewrite的最小文件size
auto-aof-rewrite-min-size 64mb

#  是否加载不完整的aof文件来进行启动
aof-load-truncated yes

aof-use-rdb-preamble yes

# 设置lua脚本的最大运行时间，单位为毫秒
lua-time-limit 5000

#redis的slow log是一个系统OS进行的记录查询，它是超过了指定的执行时间的。
#执行时间不包括类似与client进行交互或发送回复等I/O操作，它只是实际执行指令的时间。 
#告诉redis执行时间，这个时间是微秒级的（1秒=1000000微秒），这是为了不遗漏命令。
slowlog-log-slower-than 10000

# 设置slowlog的长度，当一个新的命令被记录时，最旧的命令将会从命令记录队列中移除。
slowlog-max-len 128

# 延迟监控，用于记录等于或超过了指定时间的操作，默认是关闭状态，即值为0。
latency-monitor-threshold 0

# 事件通知，默认不启用，具体参数查看配置文件
notify-keyspace-events ""

# 当条目数量较少且最大不会超过给定阀值时，哈希编码将使用一个很高效的内存数据结构，阀值由以下参数来进行配置。
hash-max-ziplist-entries 512
hash-max-ziplist-value 64

# 与哈希类似，少量的lists也会通过一个指定的方式去编码从而节省更多的空间，它的阀值通过以下参数来进行配置。
list-max-ziplist-size -2

list-compress-depth 0

# 集合sets在一种特殊的情况时有指定的编码方式，这种情况是集合由一组10进制的64位有符号整数范围内的数字组成的情况。以下选项可以设置集合使用这种特殊编码方式的size限制
set-max-intset-entries 512

# 与哈希和列表类似，有序集合也会使用一种特殊的编码方式来节省空间，这种特殊的编码方式只用于这个有序集合的长度和元素均低于以下参数设置的值时。 
zset-max-ziplist-entries 128
zset-max-ziplist-value 64

#　设置HyeperLogLog的字节数限制，这个值通常在0~15000之间，默认为3000，基本不超过16000 
hll-sparse-max-bytes 3000

stream-node-max-bytes 4096
stream-node-max-entries 100

#  redis将会在每秒中抽出10毫秒来对主字典进行重新散列化处理，这有助于尽可能的释放内存
activerehashing yes

# 因为某些原因，client不能足够快的从server读取数据，那client的输出缓存限制可能会使client失连
# 这个限制可用于3种不同的client种类，分别是：normal、slave和pubsub。 
# 格式如下
# client-output-buffer-limit <class><hard limit><soft limit><soft seconds>
# 如果达到hard limit那client将会立即失连。
# 如果达到soft limit那client将会在soft seconds秒之后失连。
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit replica 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60

# redis使用一个内部程序来处理后台任务，例如关闭超时的client连接，清除过期的key等等。它并不会同时处理所有的任务，redis通过指定的hz参数去检查和执行任务。 
# hz默认设为10，提高它的值将会占用更多的cpu，当然相应的redis将会更快的处理同时到期的许多key，以及更精确的去处理超时。 
# hz的取值范围是1~500，通常不建议超过100，只有在请求延时非常低的情况下可以将值提升到100。 
hz 10


dynamic-hz yes

#　当一个子进程要改写AOF文件，如果以下选项启用，那文件将会在每产生32MB数据时进行同步，这样提交增量文件到磁盘时可以避免出现比较大的延迟。 
aof-rewrite-incremental-fsync yes

rdb-save-incremental-fsync yes



# activedefrag yes

# active-defrag-ignore-bytes 100mb

# active-defrag-threshold-lower 10

# active-defrag-threshold-upper 100

# active-defrag-cycle-min 5

# active-defrag-cycle-max 75

# active-defrag-max-scan-fields 1000

################################# 主从复制 #################################
 
# 主从复制。使用 slaveof 来让一个 redis 实例成为另一个reids 实例的副本。
# 注意这个只需要在 slave 上配置。
# 【集群的时候需要配置】
#
# slaveof <masterip> <masterport>
 
# 如果 master 需要密码认证，就在这里设置
# 【master设置密码时需要设置】
#
# masterauth <master-password>
 
# 当一个 slave 与 master 失去联系，或者复制正在进行的时候，
# slave 可能会有两种表现：
# 1) yes时：从服务器可以响应客户端请求
# 2) no 时：从服务器将阻塞所有请求，有客户端请求时返回“SYNC with master in progress”；
#
# slave-serve-stale-data yes

# 你可以配置一个 slave 实体是否接受写入操作。
# 通过写入操作来存储一些短暂的数据对于一个 slave 实例来说可能是有用的，
# 因为相对从 master 重新同步数而言，据数据写入到 slave 会更容易被删除。
# 但是如果客户端因为一个错误的配置写入，也可能会导致一些问题。
# 从 redis 2.6 版起，默认 slaves 都是只读的。
# 注意：只读的 slaves 没有被设计成在 internet 上暴露给不受信任的客户端。
# 它仅仅是一个针对误用实例的一个保护层。
#
# slave-read-only yes

# Slaves 在一个预定义的时间间隔内发送 ping 命令到 server 。
# 你可以改变这个时间间隔。默认为 10 秒。
#
# repl-ping-slave-period 10

# 设置主从复制过期时间
# 这个值一定要比 repl-ping-slave-period 大
#
# repl-timeout 60

# 设置主从复制容量大小。这个 backlog 是一个用来在 slaves 被断开连接时
# 存放 slave 数据的 buffer，所以当一个 slave 想要重新连接，通常不希望全部重新同步，
# 只是部分同步就够了，仅仅传递 slave 在断开连接时丢失的这部分数据。
# 这个值越大，salve 可以断开连接的时间就越长。
#
# repl-backlog-size 1mb
 
# 在某些时候，master 不再连接 slaves，backlog 将被释放。
# 如果设置为 0 ，意味着绝不释放 backlog 。
#
# repl-backlog-ttl 3600
 
# 当 master 不能正常工作的时候，Redis Sentinel 会从 slaves 中选出一个新的 master，
# 这个值越小，就越会被优先选中，但是如果是 0 ， 那是意味着这个 slave 不可能被选中。
#
# 默认优先级为 100。
#slave-priority 100
################################# 集群配置 #################################


```

### 2.4.3  配置文件启动

```shell
bind 0.0.0.0
requirepass 123456
protected-mode yes
port 6379
tcp-backlog 511
timeout 0
tcp-keepalive 60
daemonize no
supervised no
pidfile /var/run/redis_6379.pid
loglevel notice
logfile "/usr/local/software/redis/log/redis.log"
databases 16
always-show-logo yes
save ""
stop-writes-on-bgsave-error yes
rdbcompression yes
rdbchecksum yes
dbfilename dump.rdb
dir /usr/local/software/redis/data
replica-serve-stale-data yes
replica-read-only yes
repl-diskless-sync no
repl-diskless-sync-delay 5
repl-disable-tcp-nodelay no
replica-priority 100
lazyfree-lazy-eviction no
lazyfree-lazy-expire no
lazyfree-lazy-server-del no
replica-lazy-flush no
appendonly yes
appendfilename "redisAofLog.aof"
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
aof-load-truncated yes
aof-use-rdb-preamble yes
lua-time-limit 5000
slowlog-log-slower-than 10000
slowlog-max-len 128
latency-monitor-threshold 0
notify-keyspace-events ""
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
list-max-ziplist-size -2
list-compress-depth 0
set-max-intset-entries 512
zset-max-ziplist-entries 128
zset-max-ziplist-value 64
hll-sparse-max-bytes 3000
stream-node-max-bytes 4096
stream-node-max-entries 100
activerehashing yes
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit replica 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60
hz 10
dynamic-hz yes
aof-rewrite-incremental-fsync yes
rdb-save-incremental-fsync yes
```



```shell
# 小知识
大约在0.6版，privileged被引入docker。
使用该参数，container内的root拥有真正的root权限。
否则，container内的root只是外部的一个普通用户权限。
privileged启动的容器，可以看到很多host上的设备，并且可以执行mount。
甚至允许你在docker容器中启动docker容器。
--privileged=true

# 凡是涉及到没有权限的错误考虑目录或者文件加权限
```



```shell
# 需要先创建以下三个文件夹，并且日志文件还要设置权限 chmod 7 redis.log
mkdir /usr/local/software
mkdir /usr/local/software/redis
mkdir /usr/local/software/redis/data
'因为容器都是默认外部用户访问，所以要给外部用户添加写权限,否则无法在该目录下创建AOF文件'
chmod 777 /usr/local/software/redis/data 
mkdir /usr/local/software/redis/conf
vi /usr/local/software/redis/conf/redis.conf `把上面的配置文件粘贴进去`
mkdir /usr/local/software/redis/log
touch /usr/local/software/redis/log/redis.log
chmod 777 /usr/local/software/redis/log/redis.log

docker run -p 6379:6379 --name redis -v /usr/local/software/redis/conf:/usr/local/software/redis/conf -v /usr/local/software/redis/data:/usr/local/software/redis/data  -v /usr/local/software/redis/log:/usr/local/software/redis/log -di redis redis-server /usr/local/software/redis/conf/redis.conf 

# 设置密码 高版本必须设置密码，设置为空redis会连接不上
config set requirepass ""
# 查询密码
config get requirepass
# 查看docker日志
docker logs redis

'当修改配置文件后，只需要重启容器即可，会默认以配置文件运行'
docker restart redis 
```

### 2.4.4  脚本安装

> 复制的时候可能第一行会消失，注意一下，脚本中想要在文本输出单引号有两种方式
>
> 1. 向左的斜杠转移
> 2. 用单引号包起来 

```shell
#!/bin/bash
# auther： zhangHongLu
docker pull redis:latest
mkdir /usr/local/software
mkdir /usr/local/software/redis
mkdir /usr/local/software/redis/data
chmod 777 /usr/local/software/redis/data 
mkdir /usr/local/software/redis/conf
touch /usr/local/software/redis/conf/redis.conf 
echo "
bind 0.0.0.0
requirepass 123456
protected-mode yes
port 6379
tcp-backlog 511
timeout 0
tcp-keepalive 60
daemonize no
supervised no
pidfile /var/run/redis_6379.pid
loglevel notice
logfile \"/usr/local/software/redis/log/redis.log\"
databases 16
always-show-logo yes
save \"\"
stop-writes-on-bgsave-error yes
rdbcompression yes
rdbchecksum yes
dbfilename dump.rdb
dir /usr/local/software/redis/data
replica-serve-stale-data yes
replica-read-only yes
repl-diskless-sync no
repl-diskless-sync-delay 5
repl-disable-tcp-nodelay no
replica-priority 100
lazyfree-lazy-eviction no
lazyfree-lazy-expire no
lazyfree-lazy-server-del no
replica-lazy-flush no
appendonly yes
appendfilename \"redisAofLog.aof\"
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
aof-load-truncated yes
aof-use-rdb-preamble yes
lua-time-limit 5000
slowlog-log-slower-than 10000
slowlog-max-len 128
latency-monitor-threshold 0
notify-keyspace-events \"\"
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
list-max-ziplist-size -2
list-compress-depth 0
set-max-intset-entries 512
zset-max-ziplist-entries 128
zset-max-ziplist-value 64
hll-sparse-max-bytes 3000
stream-node-max-bytes 4096
stream-node-max-entries 100
activerehashing yes
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit replica 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60
hz 10
dynamic-hz yes
aof-rewrite-incremental-fsync yes
rdb-save-incremental-fsync yes
" > /usr/local/software/redis/conf/redis.conf
mkdir /usr/local/software/redis/log
touch /usr/local/software/redis/log/redis.log
chmod 777 /usr/local/software/redis/log/redis.log

docker run -p 6379:6379 --name redis -v /usr/local/software/redis/conf:/usr/local/software/redis/conf -v /usr/local/software/redis/data:/usr/local/software/redis/data  -v /usr/local/software/redis/log:/usr/local/software/redis/log -di redis redis-server /usr/local/software/redis/conf/redis.conf 

```

### 2.4.5 AOF备份文件恢复

```shell
# 被攻击后修改AOF文件，
Bad file format reading the append only file: make a backup of your AOF file, then use ./redis-check-aof --fix <filename>
# 修复AOF：有可能会把AOF清空
/usr/local/bin/redis-check-aof --fix redisAofLogBuk.aof
```



## 2.5 FastDFS

### 2.5.1安装

单机版：

```shell
# 下载镜像
docker pull mypjb/fastdfs
# 创建宿主机保存fastdfs文件目录
 mkdir -p /root/data/fastdfs
# 创建容器
docker run --add-host fastdfs.net:106.52.164.198 --name fastdfs --net=host -e TRACKER_ENABLE=1 -e NGINX_PORT=81 -v /root/data/fastdfs:/storage/fastdfs -it mypjb/fastdfs
# 会进入容器内部
exit
# 运行fastdfs
docker restart fastdfs
# storage默认端口12041，tracker默认端口12050

```

集群版：

```shell
# 下载镜像
docker pull delron/fastdfs
# 也可以直接加载备份的镜像文件（二选一）
docker load -i 文件路径/fastdfs_docker.tar
---------------------------------------------- tracker ---------------------------------------------

#　运行tracker，并把运行目录挂载到宿主机目录
docker run -dti --network=host --name tracker -v /usr/local/software/tracker:/var/fdfs delron/fastdfs tracker
# tracker.conf所在目录
cd /etc/fdfs
# 修改配置文件【省略】
vi /etc/fdfs/tracker.conf
###修改内容如下，以下内容都是单机版docker配置好了的【省略】
disabled=false              # 启用配置文件
port=22122                  # tracker服务器端口（默认22122）
base_path=/var/fdfs         # 存储日志和数据的根目录

---------------------------------------------- storage ---------------------------------------------
# 运行storage
docker run -dti --network=host --name storage -e TRACKER_SERVER=106.52.164.198:22122 -v /usr/local/software/storage:/var/fdfs delron/fastdfs storage
`可以用下面这个镜像`
docker pull ygqygq2/fastdfs-nginx
docker run -dti --network=host --name storage -e TRACKER_SERVER=106.52.164.198:22122 -v /usr/local/software/storage:/var/fdfs ygqygq2/fastdfs-nginx  storage

--------------------------------------------------------------------------------------------------
-初次启动，会在/var/fdfs目录下生成logs、data两个目录。
# 进入存储数据的目录【省略】
docker exec -it storage /bin
cd /var/fdfs
# 修改配置文件[不需要修改，在运行时指定过的]【省略】
vi /etc/fdfs/storage.conf
# 修改部分内容如下
disabled=false                      `启用配置文件`
port=23000                          `storage服务端口`
base_path=/var/fdfs                 `数据和日志文件存储根目录`
store_path0=/var/fdfs               `第一个存储目录`
tracker_server=106.52.164.198:22122 `tracker服务器IP和端口,此处是上面预定好的 ip`
http.server_port=80                 `http访问文件的端口,此处需要和后面 nginx 监听端口保持一致`
# 查看日志文件
docker exec -it storage /bin/bash
vi /var/fdfs/logs/storaged.log
---------------------------------------------- client ---------------------------------------------

# 修改Tracker服务器客户端配置文件
docker exec -it tracker /bin/bash
vi /etc/fdfs/client.conf
# 修改以下配置，其它保持默认【需要修改】
base_path=/var/fdfs  
tracker_server=106.52.164.198:22122 '修改为tracker_server外网地址和端口'
# 执行测试,在tracker容器里面测试，所以需要上传一个文件到挂载目录下用作测试文件。
- 1.先进入宿主机tracker的挂载目录，往里面上传一张图片
- 2.进入tracker容器，执行下面命令
/usr/bin/fdfs_upload_file /etc/fdfs/client.conf /var/fdfs/test.jpg
`成功返回 group1/M00/00/00/rBAAAl2EoqqAFHl1AABU2guxW84193.jpg`
'游览器直接storage+返回的字符串访问'
- http://106.52.164.198:23000/group1/M00/00/00/rBAAAl2HdA2AT0y5AAUk3AZvDxY820.jpg
# docker安装的storage会自己安装好nginx模块，可以打开修改一下内容
'最好不适用按照好的，自己在容器中重新安装一下'
docker exec -it storage /bin/bash
vi /etc/fdfs/mod_fastdfs.conf
#修改以下配置 其他配置默认即可
connect_timeout=10                  # 客户端访问文件连接超时时长（单位：秒）需要该
base_path=/tmp                      # 临时目录 默认
tracker_server=106.52.164.198:22122 # tracker服务IP和端口                 需要改
storage_server_port=23000           # storage服务端口  默认
group_name=group1                   # 组名
url_have_group_name=true            # 访问链接前缀加上组名                 需要改
store_path0=/var/fdfs               # 文件存储路径
# 创建软链接
ln -s /var/fdfs/data/ /var/fdfs/data/M00
# 修改nginx.conf
vi /tmp/nginx/nginx-1.12.2/conf/nginx.conf

`需要修改的内容`
user  root;
worker_processes 1;
events {
    worker_connections 1024;
}
http {
    include mime.types;
    default_type application/octet-stream;
    sendfile on;
    keepalive_timeout 65;
    server {
    	##此处和前面storage.conf配置的 http.server 保持一致
        listen 80;
        server_name 106.52.164.198;
        ##配置通配符,将/group 开头的地址映射到 fastdfs 的项目,如果#只有一个 group1 可以直接写 group1
        location ~/group([0-9])/M00 {
            ngx_fastdfs_module;
        }
        
        error_page 500 502 503 504 /50x.html;
        location = /50x.html {
            root html;
        }
    }
}
# 重启nginx，这里有个坑，一般来说nginx运行文件都在bin目录下，但是这里在objs下
/tmp/nginx/nginx-1.12.2/objs/nginx -s reload
`出现ngx_http_fastdfs_set pid=xxx说明启动成功`
```

### 2.5.2指令

```shell
# 查看是否启动成功
ps -ef | grep fdfs_storaged
```

### 2.5.3问题

1. docker安装tracker和storage的主机地址怎么写？

   > 启动镜像后在局域网其他机器无法通过fastdfs-java-client上传文件，获取的storage的IP地址为容器的IP地址，局域网其他机器无法访问容器的IP地址，查找了很多资料包括：docker-proxy  iptables 等最终解决问题，记录下来方便。

   ```shell
   使用了docker run -d --name=rule-service --network=host就说明容器就是主机
   `当tracker和storage还有client在一台主机上时，可以把他们都想象成独立的主机。统一在外网的大环境下，ip地址一样只是端口不同。如果是不同的主机，那么直接写主机的外网ip即可。`
   ```

   

2. docker run -d --name=rule-service --network=host -p 8013:8080 sino:rule-service 只要是加上--network=host docker 启动后指定的 8013 端口就不生效，就是起来后 port 那里是空的，之前还好好的，今天突然不行了这是为啥

```shell
`host 不存在端口映射的吧，你容器中暴露的什么端口，宿主机就是什么端口。可以理解为当前容器就是主机。
```

3. storage容器启动但是马上又关闭

```shell
# 退出原因
- 1.docker容器运行必须有一个前台进程， 如果没有前台进程执行，容器认为空闲，就会自行退出
- 2.容器运行的命令如果不是那些一直挂起的命令（ 运行top，tail、循环等），就是会自动退出
- 3.这个是 docker 的机制问题
# 解决方案
docker run -dit storage /bin/bash
`就是把容器运行时di变成dit，这样就能启动一个一直停留在后台运行的storage了。
```

4. 能够上传图片，但是有游览器无法直接访问。

```shell
`vi /etc/fdfs/mod_fastdfs.conf，下面tracker_server写成tracker_server=106.52.164.198:22122：22122
tracker_server=106.52.164.198:22122
`vi /etc/fdfs/storage.conf`
http.server_port=80
```

5. 查看nginx日志，发现端口被占用

> bind() to 0.0.0.0:8080 failed (98: Address already in use)

```shell
# 查看端口被谁占用
netstat -ltunp 
```



## 2.6 JDK1.8

```shell
export  JAVA_HOME=/usr/local/software/jdk/jdk-11.0.4
export  JRE_HOME=/usr/local/software/jdk/jdk-11.0.4/jre
export  PATH=$JAVA_HOME/bin:$PATH

source /etc/profile

# 检测
java -version
```



### 2.6.1安装

```shell
----------------------------------- 直接pull --------------------------------------------------------
# 查询可用镜像，查看描述信息，看看镜像里面有哪些内容
docker search jdk
# 下载对象，并不需要创建容器
docker pull kdvolder/jdk8
----------------------------------- 手动创建 --------------------------------------------------------
# 安装centOS系统镜像：以centos7为例，因为镜像运行的时候，会用当前系统的各种资源，所以镜像只有60M大小
docker pull centos:7
'镜像不存在会自动下载'
# 宿主机创建jdk1.8目录，上传jdk-8u11-linux-x64.tar.gz到该目录，并创建Dockerfile【固定名字】
mkdir /usr/local/software/jdk1.8
vim /usr/local/software/jdk1.8/Dockerfile
`文件写入以下内容`
# 镜像名[:版本号]
from centos:7
# 作者信息
MAINTAINER goodApe
# 执行linux命令
run mkdir /usr/local/software
run mkdir /usr/local/software/jdk
# 选工作区
workdir /usr/local/software/jdk
# 把宿主机jar拷贝到容器中并解压
add jdk-8u11-linux-x64.tar.gz /usr/local/software/jdk
# 配置环境变量
env JAVA_HOME /usr/local/software/jdk/jdk1.8.0_11
env JRE_HOME /usr/local/software/jdk/jdk1.8.0_11/jre
env PATH $JAVA_HOME/bin:$PATH
# 宿主机当前目录下执行命令创建镜像
docker build -t jdk1.8 .
'【注意】空格和点都不能少，这个点代表当前目录下去构建'

```

### 2.6.2 脚本安装（未完成）

```shell
#!/bin/bash
# 张鸿璐
docker pull centos:7
yum install wget
mkdir /usr/local/software
mkdir /usr/local/software/jdk11
cd /usr/local/software/jdk11 
wget --user=979561583@qq.com --password=Weiaini988778 https://download.oracle.com/otn/java/jdk/11.0.5+10/e51269e04165492b90fa15af5b4eb1a5/jdk-11.0.5_linux-x64_bin.tar.gz


```



### 2.6.3问题

1. dockerfile指定基础镜像，比如centos，就需要先用docker下载centos镜像
2. 执行run mkdir /usr/local/software/jdk报错，说不能创建指定目录

> mkdir: cannot create directory '/usr/local/software/jdk': No such file or directory
>
> The command '/bin/sh -c mkdir /usr/local/software/jdk' returned a non-zero code: 1

```shell
`因为默认不能一次创建software和jdk两个目录，只能先创建software文件夹，再在software文件夹下面创建jdk`
```

## 2.7 Jenkins

![img](images\自动化部署)

> 作用：Jenkins是一个开源项目，提供了一种易于使用的持续集成系统，使开发者从繁杂的集成中解脱出来，专注于更为重要的业务逻辑实现上。同时Jenkins能实施监控集成中存在的错误，提供详细的日志文件和提醒功能，还能用图表的形式形象地展示项目构建的趋势和稳定性。并且Jenkins提供了大量的插件，能够完成各种任务。
>
> 依赖jdk和tomcat，也就是使用java写的，可以使用jps.

```shell
`网上不建议docker安装jenkins。因为jenkins内要使用docker，使用宿主机的。如果用docker安装jenkins那么需要挂载 Docker 给 Jenkins Image。所以为了方便这里直接安装到宿主机`
'有个问题，就是jenkins依赖于jdk8和tomcat，所以宿主机上也要安装jdk8和tomcat，但是我觉得这种方式麻烦'
'我能不能通过Dockerfile，选定基础镜像，配置好参数来完成操作，jenkins就是一个war包直接发布到webapp下'

```

### 2.7.1安装

```shell
# 编写dockerfile下载
`dockerfile开始`
FROM jenkins
USER root
#清除了基础镜像设置的源，切换成腾讯云的jessie源
#使用非腾讯云环境的需要将 tencentyun 改为 aliyun
RUN echo '' > /etc/apt/sources.list.d/jessie-backports.list \
  && echo "deb http://mirrors.tencentyun.com/debian jessie main contrib non-free" > /etc/apt/sources.list \
  && echo "deb http://mirrors.tencentyun.com/debian jessie-updates main contrib non-free" >> /etc/apt/sources.list \
  && echo "deb http://mirrors.tencentyun.com/debian-security jessie/updates main contrib non-free" >> /etc/apt/sources.list
#更新源并安装缺少的包
RUN apt-get update && apt-get install -y libltdl7 && apt-get update
ARG dockerGid=999
RUN echo "docker:x:${dockerGid}:jenkins" >> /etc/group 
# 安装 docker-compose 因为等下构建环境的需要
RUN curl -L https://github.com/docker/compose/releases/download/1.16.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose
RUN chmod +x /usr/local/bin/docker-compose
`dockerfile结束`
# 创建一个Jenkins的配置目录，并且挂载到docker 里的Jenkins目录下
mkdir -p /var/jenkins_home
# 修改目录权限（很重要！）
chown -R 1000 /var/jenkins_home
# 运行Jenkins
docker run --name jenkins -p 8080:8080 -p 50000:50000 \
    -v /var/run/docker.sock:/var/run/docker.sock \
    -v $(which docker):/bin/docker \
    -v /var/jenkins_home:/var/jenkins_home \
    -d auto-jenkins
`/var/run/docker.sock是默认的docker安装目录，无需修改。这里说明宿主机和容器都安装有docker`
`$(which docker)自动搜索docker并映射`
`映射自己配置的Jenkins_home`
'出现1665a327883e344a4a2dabc0e7a34550f8d7e3801980f8a71a870176a8e71ca8说明启动成功'
# 访问Jenkins
http://106.52.164.198:8080
# 第一次访问需要密码，进入Jenkins容器内部获取密码
docker exec -it jenkins /bin/bash
cat /var/jenkins_home/secrets/initialAdminPassword
'返回的密码6d8eb8ac5a1843889cb2334794f280c1'
# 登录后直接点击Install suggested plugins进行插件安装
# 安装完成后进入注册用户界面
'账号:admin'
'密码:123456'
# 如果注册跳转后右上角有错误信息，是需要更新版本
# 如果更新后出现警告，点击蓝色字体，进去把协议√都去掉
# 配置加速器
`【系统管理】-> 【插件管理】-> 【高级】-> 【升级站点】`
http://mirror.xmission.com/jenkins/updates/current/update-center.json
```



### 2.7.2问题

1. Problem accessing /Jenkins. Reason:

> 这是一个Jenkins的Bug。临时解决方法是：在浏览器中手工输入：http://<ip>:<port>
> 。不要访问"/jenkins"这个路径。
>
> 直接访问:http://106.52.164.198:8080

## 2.8 rancher

> Rancher是一个开源的企业级容器管理平台。通过Rancher，企业再也不必自己使用一系列的开源软件去从头搭建容器服务平台。Rancher提供了在生产环境中使用的管理Docker和Kubernetes的全栈化容器部署与管理平台。
>
> 在原来, 如果我们需要做一个分布式集群我们需要学习一全套的框架并编码实现如 服务发现, 负载均衡等逻辑, 给开发者造成很大的负担, 不过好在现在有Docker以及他周边的一些技术能在上层解决这些问题, 而应用该怎么开发就怎么开发.
>
> 当你选择使用Docker技术栈的时候, 会发现在生产环境中不光光是 `docker run`就能解决的. 还需要考虑比如docker之间的组网, 缩扩容等问题, 于是你去学习kubernetes, 发现好像有点复杂啊, 有没有更傻瓜化一点的? 那就是rancher了.

```shell
# 下载rancher
docker pull rancher/server
# 运行容器
docker run -id --name rancher -p 1111:1111 rancher/server
# 访问网址
106.52.164.198:1111
```

## 2.9 gitlab

### 2.9.1安装

```shell
# 拉取
docker pull twang2218/gitlab-ce-zh
# 通常会将 GitLab 的配置 (etc) 、 日志 (log) 、数据 (data) 放到容器之外， 便于日后升级
mkdir /usr/local/software
mkdir /usr/local/software/gitlab
mkdir /usr/local/software/gitlab/etc
mkdir /usr/local/software/gitlab/log
mkdir /usr/local/software/gitlab/data
# 开启容器
docker run -di -p 8443:443 -p 8090:80 --name gitlab -v /usr/local/software/gitlab/etc:/etc/gitlab -v /usr/local/software/gitlab/log:/var/log/gitlab -v /usr/local/software/gitlab/data:/var/opt/gitlab twang2218/gitlab-ce-zh
'-d:在后台运行容器并打印容器ID'
'-p 宿主机端口:容器端口  将容器端口发布到主机'
'--name 为容器指定名称'
# 访问
http://198.168.0.11:8090
```

### 2.9.2开启邮件

> 配置邮箱服务的用途:
>  - 有合并请求时，邮件通知
>  - 账号注册时，邮件验证
>  - 修改密码时，通过邮件修改

![1569295102640](image\1569295102640.png)

![1569295133916](image\1569295133916.png)

```shell
----------------------------------------------- 网易方式 -------------------------------------------
# 保存授权码：bdiohamlotbfcafa 
# 进入容器中配置
docker exec -it gitlab /bin/bash
vi /etc/gitlab/gitlab.rb
`安装内容`
gitlab_rails['smtp_enable'] = true
		gitlab_rails['smtp_address'] = "smtp.qq.com"
		gitlab_rails['smtp_port'] = 465
		gitlab_rails['smtp_user_name'] = "526173289@qq.com"
		gitlab_rails['smtp_password'] = "bdiohamlotbfcafa"
		gitlab_rails['smtp_domain'] = "qq.com"
		gitlab_rails['smtp_authentication'] = "login"
		gitlab_rails['smtp_enable_starttls_auto'] = true
		gitlab_rails['smtp_tls'] = true

		user['git_user_email'] = "526173289@qq.com"
		`发件者邮箱`
gitlab_rails['gitlab_email_from'] = '526173289@qq.com'
# 重新加载配置文件
gitlab-ctl reconfigure
# 测试邮件是否正常
gitlab-rails console
Notify.test_email('接收方邮件地址','邮件标题','邮件内容').deliver_now
- Notify.test_email('526173289@qq.com','gitlab测试邮件','你好啊，邮件安装成功').deliver_now
-------------------------------------- 百度方式 ----------------------------------------
# gitlab.yml中开启邮件服务以及配置由哪个账号发送
vi /var/opt/gitlab/gitlab-rails/etc/gitlab.yml
`修改以下内容`
email_enabled: true
email_from: 526173289@qq.com
# 配置smtp的用户名和密码
vi /opt/gitlab/embedded/service/gitlab-rails/config/initializers/smtp_settings.rb.sample
`修改以下内容`
if Rails.env.production?
  Rails.application.config.action_mailer.delivery_method = :smtp

  ActionMailer::Base.delivery_method = :smtp
  ActionMailer::Base.smtp_settings = {
    address: "526173289@qq.com",
    port: 465,
    user_name: "smtp",
    password: "bdiohamlotbfcafa",
    domain: "qq.com",
    authentication: :login,
    enable_starttls_auto: true,
    openssl_verify_mode: 'none' # See ActionMailer documentation for other possible options
  }
end
#　配置环境
vi /opt/gitlab/embedded/service/gitlab-rails/config/environments/production.rb
config.action_mailer.delivery_method = :smtp
config.action_mailer.smtp_settings = {
:address => "smtp.qq.com",
:port => "465",
:domain => "qq.com",
:authentication => :plain,
:user_name => "526173289@qq.com",
:password => "bdiohamlotbfcafa",
:enable_starttls_auto => true
}
# 重启gitlab
gitlab-ctl reconfigure
# 开启用户注册时邮箱确认机制
--扳手 --设置  --注册限制 --注册时发送确认邮件 --保存
```

![1569298585427](image\1569298585427.png)



### 2.9.3使用

```shell
`管理员账户:root`
`密码:cqxiande`
```

![1569298366869](image\1569298366869.png)

1. 创建组

   > #### 群组是几个项目的集合。
   >
   > 如果您在一个群组下组织项目，它的工作方式就像一个文件夹。
   >
   > 您可以管理群组成员的权限并访问群组中的每个项目。

![1569298874645](image\1569298874645.png)

![1569299046248](image\1569299046248.png)

![1569299270596](image\1569299270596.png)

2. 邀请成员

![1569299346310](image\1569299346310.png)

![1569299454501](image\1569299454501.png)

3. 创建项目

![1569300080293](image\1569300080293.png)

![1569300104287](image\1569300104287.png)

![1569300210285](image\1569300210285.png)

4. SSH连接：企业中用的较多, **SSH比https好处在于无需验证** 

```shell
#　本地电脑中打开图形界面
ssh-keygen -t rsa -C '526173289@qq.com'
`提醒你输入key的名称，输入如id_rsa,连续按两次enter即可`
'在C:\Users\用户\.ssh下产生两个文件：id_rsa和id_rsa.pub '
'用记事本打开id_rsa.pub文件，复制内容，在gitlab.com的网站上到ssh密钥管理页面'
'添加新公钥，随便取个名字，内容粘贴刚才复制的内容'
git config --global http.sslVerify false
#　本地新建文件夹开始拉去代码
git init
`ssh方式`
git remote add origin git@192.168.0.11:8090:xd/test.git
git fetch git@192.168.0.11:8090:xd/test.git
`http方式`
git remote add origin http://192.168.0.11:8090/xd/demo.git
git fetch http://192.168.0.11:8090/xd/demo.git

# 查看是http还是ssh
git remote -v 
# 是http就移除重新添加
git remote rm origin
# 提交代码
git push -u origin master
# 拉去代码
git pull master
```

5. 删除群组

![1569550811429](image\1569550811429.png)

### 2.9.4问题

1. 生成路径url是字符串不是ip地址

![1569309443707](image\1569309443707.png)

```shell
# Gitlab创建的项目改成实际服务器ip地址方法
vi /opt/gitlab/embedded/service/gitlab-rails/config/gitlab.yml
`修改一下内容，修改host 为实际 ip`
`端口也改成容器映射的主机端口8090`
gitlab:
    host: 192.168.0.11
    port: 8090
    https: false
# 重启生效
gitlab-ctl restart
'这是对ip的加密处理，不影响正常使用'
```

2.  Not a valid object name: 'master'.

```shell
'原理：刚创建的git仓库默认的master分支要在第一次commit之后才会真正建立，否则就像你声明了个对象但没初始化一样'
`先git add .添加所有项目文件到本地仓库缓存，再git commit -m "init commit"提交到本地仓库之后就可以随心所欲地创建或切换分支了。（这里给出的是可以直接操作成功的，add和commit可以按自己需要写）。`
```

3. 邮件开启了还是接收不到

```shell
'可能是用于自己把邮箱当成了垃圾邮件，要先添加信任'
```

# 3.AsciidocFX

> 书写各种复杂文档,本项目中用来作为写接口文档的工具

```shell
# 创建标题
- =        一级标题
- ==       二级标题
- ===      三级标题
# 创建目录
:sectnums:
:toc: left
:toclevels: 5 
:toc-title: 目录
#　有序列表
．点加一个空格
# 段落空一行
# 加粗
空格*加粗内容*空格
# 快捷键
ctrl + d 复制当前行
```

# 4.开发流程

确定原型 ---> 确定数据库 ---> 根据设计稿做接口或提交做接口

# 5.代码规范

```shell
1. convert可以在控制层或者service层使用
2. service层传入Dto对象，dao层写详细的每个参数，并加上param注解'是apache的注解'
3. dao一般是在做添加或者修改时传入具体的实体对象，否则就是每个参数分开写
4. 在service层对必要参数进行非空还是为空检查，检查完后构造新的实体传入dao方法
5. controller层不做非空验证，在service层做
6. 测试在单元测试里面测试，单元测试还可以上传给别人使用，也就是可以分享，所以不在controller层做太多控制
```

# 6.多模块打包

> 父pom里面添加如下内容,父模块install。没有启动类不要添加builde。但是如果有模块有映射文件或排除一些文件可以做特别添加。
>
> 直接父模块打包即可

```xml
  <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.5.1</version>
                <configuration>
                    <source>${java.version}</source>
                    <target>${java.version}</target>
                    <!-- 编码方式 -->
                    <encoding>UTF-8</encoding>
                    <!-- 略过测试代码的编译 -->
                    <skip>true</skip>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-surefire-plugin</artifactId>
                <configuration>
                    <!-- 略过整个单元测试的执行 -->
                    <skip>true</skip>
                </configuration>
            </plugin>
        </plugins>
    </build>
```

# 7.jar包运行

```shell
# 把jar包拷贝到linux系统里
nohup java -jar virtue-terminal.jar >virtue-terminal.txt  & 
1.nohup 意思是不挂断运行命令,当账户退出或终端关闭时,程序仍然运行
2.&意思是后台运行
3.>log.txt日志输出到当前路径
```

